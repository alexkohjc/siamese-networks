{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-16T05:51:57.908960Z","iopub.execute_input":"2022-03-16T05:51:57.909283Z","iopub.status.idle":"2022-03-16T05:51:57.918553Z","shell.execute_reply.started":"2022-03-16T05:51:57.909249Z","shell.execute_reply":"2022-03-16T05:51:57.917585Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# import MNIST train and test datasets\n# the test.csv dataset doesn't have the y labels; only the X variables\n# hence, to make the code reuseable; i'll declare train.csv as 'data' \n# and create the 'train' and 'test' data from it\n\ndata = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n\n# this is the 'competition scoring' data which does not have y labels; only X variables\n# X_comp = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T05:51:57.919761Z","iopub.execute_input":"2022-03-16T05:51:57.920563Z","iopub.status.idle":"2022-03-16T05:52:01.004961Z","shell.execute_reply.started":"2022-03-16T05:51:57.920520Z","shell.execute_reply":"2022-03-16T05:52:01.004074Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# RFE - Recursive Feature Elimination\n\n# from sklearn.feature_selection import RFE\n# rfe = RFE(logreg, 20)\n# rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n# print(rfe.support_)\n# print(rfe.ranking_)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T05:52:01.006106Z","iopub.execute_input":"2022-03-16T05:52:01.006329Z","iopub.status.idle":"2022-03-16T05:52:01.012373Z","shell.execute_reply.started":"2022-03-16T05:52:01.006302Z","shell.execute_reply":"2022-03-16T05:52:01.011749Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# create X and y\n# https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\nX = data.drop(labels=['label'], axis=1)\ny = data['label']\n# del data","metadata":{"execution":{"iopub.status.busy":"2022-03-16T05:52:01.013226Z","iopub.execute_input":"2022-03-16T05:52:01.013850Z","iopub.status.idle":"2022-03-16T05:52:01.134651Z","shell.execute_reply.started":"2022-03-16T05:52:01.013812Z","shell.execute_reply":"2022-03-16T05:52:01.133752Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# check for missing and null values\nX.isnull().any().describe()\n# X_comp.isnull().any().describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T05:52:01.137952Z","iopub.execute_input":"2022-03-16T05:52:01.138774Z","iopub.status.idle":"2022-03-16T05:52:01.162351Z","shell.execute_reply.started":"2022-03-16T05:52:01.138726Z","shell.execute_reply":"2022-03-16T05:52:01.161522Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"count       784\nunique        1\ntop       False\nfreq        784\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize data (to grayscale) to reduce effects of illumination and for models to converge faster\n\nX = X/255.0\n# X_comp = X_comp/255.0 # competition scoring set\n\n# check for issues with conversion\n# TODO: write tests here - assert max value <=1","metadata":{"execution":{"iopub.status.busy":"2022-03-16T05:52:01.163960Z","iopub.execute_input":"2022-03-16T05:52:01.164262Z","iopub.status.idle":"2022-03-16T05:52:01.235357Z","shell.execute_reply.started":"2022-03-16T05:52:01.164221Z","shell.execute_reply":"2022-03-16T05:52:01.234448Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X = X.to_numpy() # to_numpy() and .values is quite similar; but to_numpy() is recommended","metadata":{"execution":{"iopub.status.busy":"2022-03-16T05:52:01.236654Z","iopub.execute_input":"2022-03-16T05:52:01.236969Z","iopub.status.idle":"2022-03-16T05:52:01.241062Z","shell.execute_reply.started":"2022-03-16T05:52:01.236908Z","shell.execute_reply":"2022-03-16T05:52:01.240000Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# train-test-split\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T05:52:01.242572Z","iopub.execute_input":"2022-03-16T05:52:01.242852Z","iopub.status.idle":"2022-03-16T05:52:02.736749Z","shell.execute_reply.started":"2022-03-16T05:52:01.242815Z","shell.execute_reply":"2022-03-16T05:52:02.735991Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Models","metadata":{}},{"cell_type":"code","source":"# using LogReg instead of LogRegCV as LogRegCV doesn't seem to converge\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n# import xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\n\nfrom sklearn import metrics\n\n### fit models ###\n\n## Logistic Regression ##\n# https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8#:~:text=Logistic%20Regression%20is%20a%20Machine,%2C%20failure%2C%20etc.).\nlogreg = LogisticRegression(max_iter=1000)\nlogreg.fit(X_train, y_train)\ny_pred_logreg = logreg.predict(X_test)\n\n## Support Vector Classifier ##\n# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n# for large datasets (10s of 1000s of samples), might be better to use LinearSVC or SGDClassifier instead\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\ny_pred_svc = svc.predict(X_test)\n\n## RandomForest Classifier ##\nrf = RandomForestClassifier(\n    random_state=0\n)\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)\n\n## XGBoost ##\nxgb = XGBClassifier(label_encoder=False) # can XGB be used with X_train_3d?\nxgb.fit(X_train, y_train)\ny_pred_xgb = xgb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:29:13.212756Z","iopub.execute_input":"2022-03-16T07:29:13.213306Z","iopub.status.idle":"2022-03-16T07:41:14.259092Z","shell.execute_reply.started":"2022-03-16T07:29:13.213262Z","shell.execute_reply":"2022-03-16T07:41:14.257504Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[07:33:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","output_type":"stream"}]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix\n# confusion_matrix = confusion_matrix(y_test, y_pred)\n# print(confusion_matrix)\n\n# from sklearn.metrics import classification_report\n# print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:47:07.059575Z","iopub.execute_input":"2022-03-16T06:47:07.059911Z","iopub.status.idle":"2022-03-16T06:47:07.063836Z","shell.execute_reply.started":"2022-03-16T06:47:07.059879Z","shell.execute_reply":"2022-03-16T06:47:07.063198Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Keras Deep Neural Network","metadata":{}},{"cell_type":"code","source":"# for Keras, might have to reshape 1D vector of 784 (28*28) to 3D (28 by 28 by 1)\n# grayscale only uses 1 channel, if RGB (3 channels) reshape to 28*28*3\n\n# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train_3d = X_train.reshape(-1,28,28,1)\nX_test_3d = X_test.reshape(-1,28,28,1)\n# X_comp = X_comp.reshape(-1,28,28,1)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:38:18.158814Z","iopub.execute_input":"2022-03-16T06:38:18.159108Z","iopub.status.idle":"2022-03-16T06:38:18.164315Z","shell.execute_reply.started":"2022-03-16T06:38:18.159080Z","shell.execute_reply":"2022-03-16T06:38:18.163136Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# keras requires y labels to be one-hot endcoded: \n# https://blog.fastforwardlabs.com/2016/02/24/hello-world-in-keras-or-scikit-learn-versus-keras.html\n# this changes y into a vector of len 10, as it has 10 classes and is not binary (1/0)\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n\ny_train_ohe = to_categorical(y_train, num_classes=10)\ny_test_ohe = to_categorical(y_test, num_classes=10)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T06:38:19.128433Z","iopub.execute_input":"2022-03-16T06:38:19.129023Z","iopub.status.idle":"2022-03-16T06:38:24.607461Z","shell.execute_reply.started":"2022-03-16T06:38:19.128988Z","shell.execute_reply":"2022-03-16T06:38:24.606538Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(f'before transformation: {X_train.shape, X_test.shape, y_train.shape, y_test.shape}')\nprint(f'after transformation:{X_train_3d.shape, X_test_3d.shape, y_train_ohe.shape, y_test_ohe.shape}')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-16T06:39:39.967145Z","iopub.execute_input":"2022-03-16T06:39:39.967423Z","iopub.status.idle":"2022-03-16T06:39:39.972405Z","shell.execute_reply.started":"2022-03-16T06:39:39.967394Z","shell.execute_reply":"2022-03-16T06:39:39.971468Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"before transformation: ((29400, 784), (12600, 784), (29400,), (12600,))\nafter transformation:((29400, 28, 28, 1), (12600, 28, 28, 1), (29400, 10), (12600, 10))\n","output_type":"stream"}]},{"cell_type":"code","source":"# set the model for keras\n# https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\nimport tensorflow as tf\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Lambda\n# from keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:05:38.523746Z","iopub.execute_input":"2022-03-16T08:05:38.524080Z","iopub.status.idle":"2022-03-16T08:05:38.617311Z","shell.execute_reply.started":"2022-03-16T08:05:38.524020Z","shell.execute_reply":"2022-03-16T08:05:38.616352Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Model: \"sequential_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_49 (Conv2D)           (None, 28, 28, 32)        832       \n_________________________________________________________________\nconv2d_50 (Conv2D)           (None, 28, 28, 32)        25632     \n_________________________________________________________________\nmax_pooling2d_24 (MaxPooling (None, 14, 14, 32)        0         \n_________________________________________________________________\ndropout_36 (Dropout)         (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_51 (Conv2D)           (None, 14, 14, 64)        18496     \n_________________________________________________________________\nconv2d_52 (Conv2D)           (None, 14, 14, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_25 (MaxPooling (None, 7, 7, 64)          0         \n_________________________________________________________________\ndropout_37 (Dropout)         (None, 7, 7, 64)          0         \n_________________________________________________________________\nflatten_12 (Flatten)         (None, 3136)              0         \n_________________________________________________________________\ndense_24 (Dense)             (None, 256)               803072    \n_________________________________________________________________\ndropout_38 (Dropout)         (None, 256)               0         \n_________________________________________________________________\ndense_25 (Dense)             (None, 10)                2570      \n=================================================================\nTotal params: 887,530\nTrainable params: 887,530\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the optimizer\n# optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n# Compile the model\n# model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nmodel.compile(\n    optimizer = tf.keras.optimizers.Adam(0.001), # we can also use the RMSprop() as the optimizer\n    # Loss Function to minimize\n    loss = \"categorical_crossentropy\", # keras.losses.SparseCategoricalCrossentropy()\n    # List of metrics to monitor\n    metrics=[\"accuracy\"] # keras.metrics.SparseCategoricalAccuracy()\n)\n\n# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:05:41.071786Z","iopub.execute_input":"2022-03-16T08:05:41.072592Z","iopub.status.idle":"2022-03-16T08:05:41.082688Z","shell.execute_reply.started":"2022-03-16T08:05:41.072556Z","shell.execute_reply":"2022-03-16T08:05:41.081759Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"batch_size = 86\nepochs = 1\nverbose = 2","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:05:41.382808Z","iopub.execute_input":"2022-03-16T08:05:41.383273Z","iopub.status.idle":"2022-03-16T08:05:41.387586Z","shell.execute_reply.started":"2022-03-16T08:05:41.383226Z","shell.execute_reply":"2022-03-16T08:05:41.386976Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"history_nn = model.fit(\n    X_train_3d,\n    y_train_ohe,\n    batch_size=batch_size,\n    epochs=epochs, # Turn epochs to 30 to get 0.9967 accuracy\n    validation_data=(X_test_3d, y_test_ohe),\n    verbose=verbose\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:05:42.148017Z","iopub.execute_input":"2022-03-16T08:05:42.148515Z","iopub.status.idle":"2022-03-16T08:06:39.376008Z","shell.execute_reply.started":"2022-03-16T08:05:42.148470Z","shell.execute_reply":"2022-03-16T08:06:39.374599Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"342/342 - 57s - loss: 0.3032 - accuracy: 0.9037 - val_loss: 0.0669 - val_accuracy: 0.9787\n","output_type":"stream"}]},{"cell_type":"code","source":"history_nn.history","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:18:40.735750Z","iopub.execute_input":"2022-03-16T08:18:40.736720Z","iopub.status.idle":"2022-03-16T08:18:40.742448Z","shell.execute_reply.started":"2022-03-16T08:18:40.736654Z","shell.execute_reply":"2022-03-16T08:18:40.741525Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"{'loss': [0.30320146679878235],\n 'accuracy': [0.9037414789199829],\n 'val_loss': [0.06685896217823029],\n 'val_accuracy': [0.9787301421165466]}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Siamese Networks","metadata":{}},{"cell_type":"code","source":"print(X_train_3d.shape, y_train_ohe.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:16:23.892136Z","iopub.execute_input":"2022-03-16T08:16:23.892405Z","iopub.status.idle":"2022-03-16T08:16:23.897330Z","shell.execute_reply.started":"2022-03-16T08:16:23.892376Z","shell.execute_reply":"2022-03-16T08:16:23.896417Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"(29400, 28, 28, 1) (29400, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"model_sn = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    tf.keras.layers.Dropout(0.3),\n    \n    tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Flatten(),\n    \n    tf.keras.layers.Dense(256, activation=None), # No activation on final dense layer\n    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n])\n\n# model_sn = Sequential([\n#     Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)),\n#     MaxPool2D(pool_size=2),\n#     Dropout(0.3),\n#     Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n#     MaxPool2D(pool_size=2),\n#     Dropout(0.3),\n#     Flatten(),\n#     Dense(256, activation=None), # No activation on final dense layer\n#     Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n# ])\n\nmodel_sn.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:15:25.654632Z","iopub.execute_input":"2022-03-16T08:15:25.655194Z","iopub.status.idle":"2022-03-16T08:15:25.714736Z","shell.execute_reply.started":"2022-03-16T08:15:25.655152Z","shell.execute_reply":"2022-03-16T08:15:25.714034Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\n\nmodel_sn.compile(\n    optimizer=tf.keras.optimizers.Adam(0.001),\n    loss=tfa.losses.TripletSemiHardLoss(), # set the loss as TripletSemiHardLoss()\n    metrics=[\"accuracy\"]\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:19:07.392458Z","iopub.execute_input":"2022-03-16T08:19:07.392772Z","iopub.status.idle":"2022-03-16T08:19:07.405166Z","shell.execute_reply.started":"2022-03-16T08:19:07.392743Z","shell.execute_reply":"2022-03-16T08:19:07.404211Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"history_sn = model_sn.fit(\n    X_train_3d,\n    y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_data=(X_test_3d, y_test),\n    verbose=verbose\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:19:08.784840Z","iopub.execute_input":"2022-03-16T08:19:08.785162Z","iopub.status.idle":"2022-03-16T08:19:26.846339Z","shell.execute_reply.started":"2022-03-16T08:19:08.785132Z","shell.execute_reply":"2022-03-16T08:19:26.845415Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"342/342 - 18s - loss: 0.6366 - accuracy: 2.3810e-04 - val_loss: 0.5007 - val_accuracy: 0.0000e+00\n","output_type":"stream"}]},{"cell_type":"code","source":"print(y_train.shape, y_test.shape)\nprint(type(y_train), type(y_test))\nprint(y_train.iloc[0], y_test.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:22:33.721859Z","iopub.execute_input":"2022-03-16T08:22:33.722720Z","iopub.status.idle":"2022-03-16T08:22:33.729208Z","shell.execute_reply.started":"2022-03-16T08:22:33.722676Z","shell.execute_reply":"2022-03-16T08:22:33.728279Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"(29400,) (12600,)\n<class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n0 3\n","output_type":"stream"}]},{"cell_type":"code","source":"history_sn.history","metadata":{"execution":{"iopub.status.busy":"2022-03-16T08:19:26.848776Z","iopub.execute_input":"2022-03-16T08:19:26.849553Z","iopub.status.idle":"2022-03-16T08:19:26.854417Z","shell.execute_reply.started":"2022-03-16T08:19:26.849516Z","shell.execute_reply":"2022-03-16T08:19:26.853654Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"{'loss': [0.6366080045700073],\n 'accuracy': [0.0002380952355451882],\n 'val_loss': [0.5007310509681702],\n 'val_accuracy': [0.0]}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Scoring","metadata":{}},{"cell_type":"code","source":"print('Accuracy on Test Set')\nprint('Logistic Regression: {:.2f}'.format(logreg.score(X_test, y_test)))\nprint('Support Vector Classifier: {:.2f}'.format(svc.score(X_test, y_test)))\nprint('RandomForest Classifier: {:.2f}'.format(rf.score(X_test, y_test)))\nprint('XGBoost Classifier: {:.2f}'.format(xgb.score(X_test, y_test)))\n\n# these are the results of the training and 'val' data, which is kinda like the 'test' data\n# some terminology differences\n# thus what we need here IIUC is the val_accuracy\nprint(\"Neural Network: {:.2f}\".format(history_nn.history.get('val_accuracy')[0]))\nprint(\"Siamese Network: {:.2f}\".format(history_sn.history.get('val_accuracy')[0]))","metadata":{"execution":{"iopub.status.busy":"2022-03-17T02:53:47.629235Z","iopub.execute_input":"2022-03-17T02:53:47.629915Z","iopub.status.idle":"2022-03-17T02:53:47.732068Z","shell.execute_reply.started":"2022-03-17T02:53:47.629788Z","shell.execute_reply":"2022-03-17T02:53:47.730726Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Accuracy on Test Set\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/4240163994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy on Test Set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Support Vector Classifier: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RandomForest Classifier: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XGBoost Classifier: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'logreg' is not defined"],"ename":"NameError","evalue":"name 'logreg' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# keras uses .evaluate() instead of .score()\n# this .evaluate() is supposed to be done on the 'competition set' IIUC\n\n# loss, accuracy = model.evaluate(X_test_3d, y_test_ohe, verbose=0)\n# print(\"Accuracy of Neural Network on test set = {:.2f}\".format(accuracy))\n\n# results = model.evaluate(X_test_3d, y_test_ohe, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:01:00.593795Z","iopub.execute_input":"2022-03-16T07:01:00.594411Z","iopub.status.idle":"2022-03-16T07:01:08.033226Z","shell.execute_reply.started":"2022-03-16T07:01:00.594370Z","shell.execute_reply":"2022-03-16T07:01:08.032467Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}